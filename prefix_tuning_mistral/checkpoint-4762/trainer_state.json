{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 4762,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020999580008399833,
      "grad_norm": 4.804351806640625,
      "learning_rate": 0.00019794204115917684,
      "loss": 10.9607,
      "step": 50
    },
    {
      "epoch": 0.041999160016799666,
      "grad_norm": 5.5233588218688965,
      "learning_rate": 0.00019584208315833685,
      "loss": 8.2104,
      "step": 100
    },
    {
      "epoch": 0.06299874002519949,
      "grad_norm": 4.385756969451904,
      "learning_rate": 0.00019374212515749686,
      "loss": 6.449,
      "step": 150
    },
    {
      "epoch": 0.08399832003359933,
      "grad_norm": 3.2379982471466064,
      "learning_rate": 0.00019164216715665688,
      "loss": 4.9709,
      "step": 200
    },
    {
      "epoch": 0.10499790004199916,
      "grad_norm": 3.4396891593933105,
      "learning_rate": 0.0001895422091558169,
      "loss": 3.9513,
      "step": 250
    },
    {
      "epoch": 0.12599748005039899,
      "grad_norm": 1.6089189052581787,
      "learning_rate": 0.0001874422511549769,
      "loss": 3.1708,
      "step": 300
    },
    {
      "epoch": 0.1469970600587988,
      "grad_norm": 3.4133260250091553,
      "learning_rate": 0.00018534229315413694,
      "loss": 2.596,
      "step": 350
    },
    {
      "epoch": 0.16799664006719867,
      "grad_norm": 3.398581027984619,
      "learning_rate": 0.00018324233515329695,
      "loss": 2.1356,
      "step": 400
    },
    {
      "epoch": 0.1889962200755985,
      "grad_norm": 7.640914440155029,
      "learning_rate": 0.00018114237715245696,
      "loss": 1.9118,
      "step": 450
    },
    {
      "epoch": 0.20999580008399832,
      "grad_norm": 3.2106027603149414,
      "learning_rate": 0.00017904241915161698,
      "loss": 1.6619,
      "step": 500
    },
    {
      "epoch": 0.23099538009239814,
      "grad_norm": 4.234104633331299,
      "learning_rate": 0.000176942461150777,
      "loss": 1.5694,
      "step": 550
    },
    {
      "epoch": 0.25199496010079797,
      "grad_norm": 5.133983612060547,
      "learning_rate": 0.00017484250314993703,
      "loss": 1.3049,
      "step": 600
    },
    {
      "epoch": 0.2729945401091978,
      "grad_norm": 4.745477199554443,
      "learning_rate": 0.00017274254514909701,
      "loss": 1.1127,
      "step": 650
    },
    {
      "epoch": 0.2939941201175976,
      "grad_norm": 1.0172538757324219,
      "learning_rate": 0.00017064258714825705,
      "loss": 1.1411,
      "step": 700
    },
    {
      "epoch": 0.3149937001259975,
      "grad_norm": 2.158066987991333,
      "learning_rate": 0.00016854262914741707,
      "loss": 0.9708,
      "step": 750
    },
    {
      "epoch": 0.33599328013439733,
      "grad_norm": 4.632125377655029,
      "learning_rate": 0.00016644267114657708,
      "loss": 0.9639,
      "step": 800
    },
    {
      "epoch": 0.35699286014279713,
      "grad_norm": 1.72796630859375,
      "learning_rate": 0.0001643427131457371,
      "loss": 0.8937,
      "step": 850
    },
    {
      "epoch": 0.377992440151197,
      "grad_norm": 2.560429573059082,
      "learning_rate": 0.0001622427551448971,
      "loss": 0.9018,
      "step": 900
    },
    {
      "epoch": 0.3989920201595968,
      "grad_norm": 2.7860186100006104,
      "learning_rate": 0.00016014279714405714,
      "loss": 0.8008,
      "step": 950
    },
    {
      "epoch": 0.41999160016799664,
      "grad_norm": 3.8040454387664795,
      "learning_rate": 0.00015804283914321713,
      "loss": 0.815,
      "step": 1000
    },
    {
      "epoch": 0.4409911801763965,
      "grad_norm": 2.9460129737854004,
      "learning_rate": 0.00015594288114237717,
      "loss": 0.8117,
      "step": 1050
    },
    {
      "epoch": 0.4619907601847963,
      "grad_norm": 2.851065158843994,
      "learning_rate": 0.00015384292314153718,
      "loss": 0.7288,
      "step": 1100
    },
    {
      "epoch": 0.48299034019319614,
      "grad_norm": 2.5527265071868896,
      "learning_rate": 0.0001517429651406972,
      "loss": 0.7582,
      "step": 1150
    },
    {
      "epoch": 0.5039899202015959,
      "grad_norm": 1.8225476741790771,
      "learning_rate": 0.0001496430071398572,
      "loss": 0.7778,
      "step": 1200
    },
    {
      "epoch": 0.5249895002099958,
      "grad_norm": 3.0387613773345947,
      "learning_rate": 0.00014754304913901722,
      "loss": 0.7262,
      "step": 1250
    },
    {
      "epoch": 0.5459890802183957,
      "grad_norm": 1.7061656713485718,
      "learning_rate": 0.00014544309113817726,
      "loss": 0.698,
      "step": 1300
    },
    {
      "epoch": 0.5669886602267955,
      "grad_norm": 1.107953667640686,
      "learning_rate": 0.00014334313313733727,
      "loss": 0.6908,
      "step": 1350
    },
    {
      "epoch": 0.5879882402351952,
      "grad_norm": 4.669509410858154,
      "learning_rate": 0.00014124317513649728,
      "loss": 0.6928,
      "step": 1400
    },
    {
      "epoch": 0.6089878202435951,
      "grad_norm": 2.3472273349761963,
      "learning_rate": 0.0001391432171356573,
      "loss": 0.6543,
      "step": 1450
    },
    {
      "epoch": 0.629987400251995,
      "grad_norm": 2.275048017501831,
      "learning_rate": 0.0001370432591348173,
      "loss": 0.6779,
      "step": 1500
    },
    {
      "epoch": 0.6509869802603948,
      "grad_norm": 1.7009859085083008,
      "learning_rate": 0.00013494330113397732,
      "loss": 0.6777,
      "step": 1550
    },
    {
      "epoch": 0.6719865602687947,
      "grad_norm": 2.0742411613464355,
      "learning_rate": 0.00013284334313313736,
      "loss": 0.6859,
      "step": 1600
    },
    {
      "epoch": 0.6929861402771944,
      "grad_norm": 1.6362420320510864,
      "learning_rate": 0.00013074338513229737,
      "loss": 0.6419,
      "step": 1650
    },
    {
      "epoch": 0.7139857202855943,
      "grad_norm": 1.6142959594726562,
      "learning_rate": 0.00012864342713145738,
      "loss": 0.6355,
      "step": 1700
    },
    {
      "epoch": 0.7349853002939941,
      "grad_norm": 3.681150197982788,
      "learning_rate": 0.0001265434691306174,
      "loss": 0.6239,
      "step": 1750
    },
    {
      "epoch": 0.755984880302394,
      "grad_norm": 1.3432674407958984,
      "learning_rate": 0.0001244435111297774,
      "loss": 0.6334,
      "step": 1800
    },
    {
      "epoch": 0.7769844603107938,
      "grad_norm": 1.6215717792510986,
      "learning_rate": 0.00012234355312893745,
      "loss": 0.6513,
      "step": 1850
    },
    {
      "epoch": 0.7979840403191936,
      "grad_norm": 1.2456132173538208,
      "learning_rate": 0.00012024359512809744,
      "loss": 0.6402,
      "step": 1900
    },
    {
      "epoch": 0.8189836203275934,
      "grad_norm": 1.9745392799377441,
      "learning_rate": 0.00011814363712725747,
      "loss": 0.6624,
      "step": 1950
    },
    {
      "epoch": 0.8399832003359933,
      "grad_norm": 1.4330339431762695,
      "learning_rate": 0.00011604367912641747,
      "loss": 0.6221,
      "step": 2000
    },
    {
      "epoch": 0.8609827803443931,
      "grad_norm": 0.9711441397666931,
      "learning_rate": 0.0001139437211255775,
      "loss": 0.6243,
      "step": 2050
    },
    {
      "epoch": 0.881982360352793,
      "grad_norm": 1.28790283203125,
      "learning_rate": 0.0001118437631247375,
      "loss": 0.6235,
      "step": 2100
    },
    {
      "epoch": 0.9029819403611927,
      "grad_norm": 1.2550536394119263,
      "learning_rate": 0.00010974380512389752,
      "loss": 0.6445,
      "step": 2150
    },
    {
      "epoch": 0.9239815203695926,
      "grad_norm": 1.1874133348464966,
      "learning_rate": 0.00010764384712305755,
      "loss": 0.6139,
      "step": 2200
    },
    {
      "epoch": 0.9449811003779924,
      "grad_norm": 0.6632778644561768,
      "learning_rate": 0.00010554388912221756,
      "loss": 0.5965,
      "step": 2250
    },
    {
      "epoch": 0.9659806803863923,
      "grad_norm": 1.349654197692871,
      "learning_rate": 0.00010344393112137758,
      "loss": 0.6134,
      "step": 2300
    },
    {
      "epoch": 0.9869802603947921,
      "grad_norm": 2.6511614322662354,
      "learning_rate": 0.00010134397312053758,
      "loss": 0.6286,
      "step": 2350
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6098222732543945,
      "eval_runtime": 130.0294,
      "eval_samples_per_second": 31.378,
      "eval_steps_per_second": 3.922,
      "step": 2381
    },
    {
      "epoch": 1.0079798404031919,
      "grad_norm": 2.209547281265259,
      "learning_rate": 9.924401511969761e-05,
      "loss": 0.6039,
      "step": 2400
    },
    {
      "epoch": 1.0289794204115918,
      "grad_norm": 1.671640157699585,
      "learning_rate": 9.714405711885762e-05,
      "loss": 0.581,
      "step": 2450
    },
    {
      "epoch": 1.0499790004199916,
      "grad_norm": 2.688539505004883,
      "learning_rate": 9.504409911801765e-05,
      "loss": 0.5935,
      "step": 2500
    },
    {
      "epoch": 1.0709785804283913,
      "grad_norm": 0.9619289636611938,
      "learning_rate": 9.294414111717766e-05,
      "loss": 0.6055,
      "step": 2550
    },
    {
      "epoch": 1.0919781604367913,
      "grad_norm": 2.7646992206573486,
      "learning_rate": 9.084418311633767e-05,
      "loss": 0.6074,
      "step": 2600
    },
    {
      "epoch": 1.112977740445191,
      "grad_norm": 1.4603554010391235,
      "learning_rate": 8.87442251154977e-05,
      "loss": 0.6283,
      "step": 2650
    },
    {
      "epoch": 1.133977320453591,
      "grad_norm": 1.42462158203125,
      "learning_rate": 8.664426711465771e-05,
      "loss": 0.5956,
      "step": 2700
    },
    {
      "epoch": 1.1549769004619908,
      "grad_norm": 1.6939489841461182,
      "learning_rate": 8.454430911381774e-05,
      "loss": 0.6262,
      "step": 2750
    },
    {
      "epoch": 1.1759764804703905,
      "grad_norm": 1.3476917743682861,
      "learning_rate": 8.244435111297775e-05,
      "loss": 0.5705,
      "step": 2800
    },
    {
      "epoch": 1.1969760604787905,
      "grad_norm": 1.937852144241333,
      "learning_rate": 8.034439311213776e-05,
      "loss": 0.6137,
      "step": 2850
    },
    {
      "epoch": 1.2179756404871902,
      "grad_norm": 3.047839403152466,
      "learning_rate": 7.824443511129777e-05,
      "loss": 0.607,
      "step": 2900
    },
    {
      "epoch": 1.2389752204955902,
      "grad_norm": 2.1788930892944336,
      "learning_rate": 7.614447711045779e-05,
      "loss": 0.5838,
      "step": 2950
    },
    {
      "epoch": 1.25997480050399,
      "grad_norm": 1.8296974897384644,
      "learning_rate": 7.404451910961781e-05,
      "loss": 0.5689,
      "step": 3000
    },
    {
      "epoch": 1.2809743805123897,
      "grad_norm": 1.2180283069610596,
      "learning_rate": 7.194456110877784e-05,
      "loss": 0.5958,
      "step": 3050
    },
    {
      "epoch": 1.3019739605207896,
      "grad_norm": 1.4974324703216553,
      "learning_rate": 6.984460310793785e-05,
      "loss": 0.5693,
      "step": 3100
    },
    {
      "epoch": 1.3229735405291894,
      "grad_norm": 1.2473247051239014,
      "learning_rate": 6.774464510709786e-05,
      "loss": 0.5999,
      "step": 3150
    },
    {
      "epoch": 1.3439731205375893,
      "grad_norm": 0.7287123799324036,
      "learning_rate": 6.564468710625787e-05,
      "loss": 0.5961,
      "step": 3200
    },
    {
      "epoch": 1.364972700545989,
      "grad_norm": 2.7566633224487305,
      "learning_rate": 6.35447291054179e-05,
      "loss": 0.5741,
      "step": 3250
    },
    {
      "epoch": 1.3859722805543888,
      "grad_norm": 1.2247083187103271,
      "learning_rate": 6.144477110457791e-05,
      "loss": 0.5781,
      "step": 3300
    },
    {
      "epoch": 1.4069718605627888,
      "grad_norm": 1.1704126596450806,
      "learning_rate": 5.934481310373793e-05,
      "loss": 0.6115,
      "step": 3350
    },
    {
      "epoch": 1.4279714405711885,
      "grad_norm": 1.200473666191101,
      "learning_rate": 5.7244855102897944e-05,
      "loss": 0.5964,
      "step": 3400
    },
    {
      "epoch": 1.4489710205795885,
      "grad_norm": 1.2135958671569824,
      "learning_rate": 5.5144897102057956e-05,
      "loss": 0.5875,
      "step": 3450
    },
    {
      "epoch": 1.4699706005879882,
      "grad_norm": 3.891474485397339,
      "learning_rate": 5.304493910121798e-05,
      "loss": 0.6072,
      "step": 3500
    },
    {
      "epoch": 1.490970180596388,
      "grad_norm": 1.5367242097854614,
      "learning_rate": 5.0944981100378e-05,
      "loss": 0.5819,
      "step": 3550
    },
    {
      "epoch": 1.511969760604788,
      "grad_norm": 2.4564640522003174,
      "learning_rate": 4.884502309953801e-05,
      "loss": 0.5638,
      "step": 3600
    },
    {
      "epoch": 1.5329693406131877,
      "grad_norm": 1.234827995300293,
      "learning_rate": 4.6745065098698026e-05,
      "loss": 0.5914,
      "step": 3650
    },
    {
      "epoch": 1.5539689206215876,
      "grad_norm": 1.6636476516723633,
      "learning_rate": 4.4645107097858045e-05,
      "loss": 0.6099,
      "step": 3700
    },
    {
      "epoch": 1.5749685006299874,
      "grad_norm": 1.4986059665679932,
      "learning_rate": 4.2545149097018064e-05,
      "loss": 0.6043,
      "step": 3750
    },
    {
      "epoch": 1.5959680806383871,
      "grad_norm": 1.4147602319717407,
      "learning_rate": 4.044519109617808e-05,
      "loss": 0.5761,
      "step": 3800
    },
    {
      "epoch": 1.616967660646787,
      "grad_norm": 1.7886896133422852,
      "learning_rate": 3.8345233095338095e-05,
      "loss": 0.5672,
      "step": 3850
    },
    {
      "epoch": 1.637967240655187,
      "grad_norm": 0.6760497689247131,
      "learning_rate": 3.624527509449811e-05,
      "loss": 0.582,
      "step": 3900
    },
    {
      "epoch": 1.6589668206635868,
      "grad_norm": 0.725968599319458,
      "learning_rate": 3.4145317093658134e-05,
      "loss": 0.5867,
      "step": 3950
    },
    {
      "epoch": 1.6799664006719865,
      "grad_norm": 1.176604986190796,
      "learning_rate": 3.2045359092818146e-05,
      "loss": 0.5694,
      "step": 4000
    },
    {
      "epoch": 1.7009659806803863,
      "grad_norm": 1.0983580350875854,
      "learning_rate": 2.9945401091978158e-05,
      "loss": 0.6009,
      "step": 4050
    },
    {
      "epoch": 1.7219655606887863,
      "grad_norm": 1.7898046970367432,
      "learning_rate": 2.784544309113818e-05,
      "loss": 0.593,
      "step": 4100
    },
    {
      "epoch": 1.7429651406971862,
      "grad_norm": 1.4551879167556763,
      "learning_rate": 2.5745485090298193e-05,
      "loss": 0.5749,
      "step": 4150
    },
    {
      "epoch": 1.763964720705586,
      "grad_norm": 1.2699074745178223,
      "learning_rate": 2.3645527089458212e-05,
      "loss": 0.5799,
      "step": 4200
    },
    {
      "epoch": 1.7849643007139857,
      "grad_norm": 0.8530053496360779,
      "learning_rate": 2.1545569088618228e-05,
      "loss": 0.5726,
      "step": 4250
    },
    {
      "epoch": 1.8059638807223855,
      "grad_norm": 1.6553117036819458,
      "learning_rate": 1.9445611087778247e-05,
      "loss": 0.5626,
      "step": 4300
    },
    {
      "epoch": 1.8269634607307854,
      "grad_norm": 1.83611261844635,
      "learning_rate": 1.7345653086938263e-05,
      "loss": 0.5517,
      "step": 4350
    },
    {
      "epoch": 1.8479630407391854,
      "grad_norm": 1.561932921409607,
      "learning_rate": 1.524569508609828e-05,
      "loss": 0.576,
      "step": 4400
    },
    {
      "epoch": 1.8689626207475851,
      "grad_norm": 1.4545708894729614,
      "learning_rate": 1.3145737085258294e-05,
      "loss": 0.5847,
      "step": 4450
    },
    {
      "epoch": 1.8899622007559849,
      "grad_norm": 1.5050592422485352,
      "learning_rate": 1.1045779084418312e-05,
      "loss": 0.5435,
      "step": 4500
    },
    {
      "epoch": 1.9109617807643846,
      "grad_norm": 1.4173046350479126,
      "learning_rate": 8.945821083578329e-06,
      "loss": 0.5924,
      "step": 4550
    },
    {
      "epoch": 1.9319613607727846,
      "grad_norm": 1.9863353967666626,
      "learning_rate": 6.845863082738345e-06,
      "loss": 0.5872,
      "step": 4600
    },
    {
      "epoch": 1.9529609407811845,
      "grad_norm": 1.5239534378051758,
      "learning_rate": 4.745905081898362e-06,
      "loss": 0.5861,
      "step": 4650
    },
    {
      "epoch": 1.9739605207895843,
      "grad_norm": 2.4001011848449707,
      "learning_rate": 2.645947081058379e-06,
      "loss": 0.5898,
      "step": 4700
    },
    {
      "epoch": 1.994960100797984,
      "grad_norm": 0.9815872311592102,
      "learning_rate": 5.459890802183957e-07,
      "loss": 0.5965,
      "step": 4750
    }
  ],
  "logging_steps": 50,
  "max_steps": 4762,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.1611461640637645e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
